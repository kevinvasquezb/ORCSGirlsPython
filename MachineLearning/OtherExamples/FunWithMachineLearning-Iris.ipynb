{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FunWithMachineLearning-Iris.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tproffen/ORCSGirlsPython/blob/master/MachineLearning/OtherExamples/FunWithMachineLearning-Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYL-XFqCNQIp"
      },
      "source": [
        "<img src=\"https://github.com/tproffen/ORCSGirlsPython/blob/master/Images/Logo.png?raw=1\" width=\"10%\" align=\"right\" hpsace=\"50\">\n",
        "\n",
        "# Machine Learning\n",
        "\n",
        "## Extra example - Fun with Machine Learning - *Iris classifier*\n",
        "\n",
        "We're going to use K-nearest neighbors and neural networks on the iris data set!  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVCrZ95TNQIr"
      },
      "source": [
        "### Loading Extensions ##\n",
        "\n",
        "A great thing about Python is that there are extensions for lots of different things you want to do, including machine learning! We're going to use several Python extensions to help us read in the data and do machine learning.  First, we'll load those libraries in.  Make sure that you execute it by using `shift-enter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW9G9uzxNQIr"
      },
      "source": [
        "import sys\n",
        "# scipy\n",
        "import scipy\n",
        "# numpy\n",
        "import numpy\n",
        "# matplotlib -- the extension that plots the data\n",
        "import matplotlib\n",
        "# pandas -- the extension that reads in the data\n",
        "import pandas\n",
        "# scikit-learn -- where the machine learning code comes from!\n",
        "import sklearn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kFraedLNQIv"
      },
      "source": [
        "### Step 1: Loading the data ##\n",
        "\n",
        "Now we're going to load the iris data into our program using pandas.  Since the data on the website doesn't have column labels telling us what each of the numbers are, we specify the names of each type of data.  In this case, \"class\" will be one of Iris-Verginica, Iris-Versicolour or Iris-Setosa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5nunVmzNQIw"
      },
      "source": [
        "# Website where the data is located -- You can visit this website to see what the raw data looks like.\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
        "\n",
        "# Read the data set from the website.\n",
        "dataset = pandas.read_csv(url, names=names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9tjTYtSNQIz"
      },
      "source": [
        "### Step 2: Look at the data ##\n",
        "\n",
        "Let's inspect the data to see what it looks like. The pandas extension has some handy methods for us to use to do that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wqh41qgNQIz"
      },
      "source": [
        "# This will tell us how many irises there are (the first number) and how many data points \n",
        "# each iris has (the second number)\n",
        "print(dataset.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l45oqMdSNQI2"
      },
      "source": [
        "# This will show us the first 20 irises in the data set.\n",
        "print(dataset.head(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKGzOtWpNQI5"
      },
      "source": [
        "Now let's find out how many there are per class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvVLy05sNQI6"
      },
      "source": [
        "# This commands groups the irises by class and prints out how many there are in each class.\n",
        "print(dataset.groupby('class').size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7je5tvfNQI8"
      },
      "source": [
        "### Step 3: Separate the data into input data and labels. ##\n",
        "\n",
        "This array has all of the data in it, including the labels.  The labels are what we're trying to get the machine learning methods to learn based on the inputs we give it, so we need to separate them.  The inputs are the first four columns (petal and sepal length and width) and the labels are the last column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-FOTBO6NQI9"
      },
      "source": [
        "# The value of the data are inside the variable dataset, so let's pull them out.\n",
        "values = dataset.values\n",
        "\n",
        "# Let's get the inputs by pulling out all of the rows and columns 0 through 4 (not including 4)\n",
        "inputs = values[:,0:4]\n",
        "\n",
        "# Let's get the labels by pullling out all of the rows and column 4\n",
        "labels = values[:,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z9UkBlFNQJA"
      },
      "source": [
        "### Step 4: Separate the data into training and testing. ##\n",
        "\n",
        "Remember that for maching learning, we always want to use training data to teach the machine learning method to do something and use the testing method to see how well it has learned.  The extension sklearn's model_selection will do this for us, but first we have to specify how much of the data we want to be testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfvDBkx3NQJB"
      },
      "source": [
        "# This says that we want 20 percent of our data to be the testing set.\n",
        "testing_size = 0.2\n",
        "\n",
        "# This is a number that is used to determine how the training/testing set is randomly split.\n",
        "# It's best to treat it as a \"magic\" number.\n",
        "seed = 7\n",
        "\n",
        "# Let's split the data into training and testing!\n",
        "inputs_train, inputs_test, labels_train, labels_test = model_selection.train_test_split(inputs, labels, test_size=testing_size, random_state=seed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaxvExJhNQJE"
      },
      "source": [
        "### Step 5: Let's train K-Nearest Neighbors! ##\n",
        "\n",
        "We'll start with K-Nearest Neighbors (KNN).  Up where we loaded the extensions, we loaded in a KNeighborsClassifier. Now we're going to create one, and then call `fit` on it, which is where the training or learning happens based on the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMoTeodCNQJF"
      },
      "source": [
        "# Create the KNN\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Train the KNN!\n",
        "knn.fit(inputs_train, labels_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksoEtxnlNQJH"
      },
      "source": [
        "### Step 6: Let's see if the KNN learned anything... ##\n",
        "\n",
        "First, we'll see if it learned the training data.  We use a method called `predict` to run data through the KNN classifier.  Then we're going to print the accuracy score and we're going to multiply it by 100.  You can think of the score that it gets like a score on a test at a school.  The higher the score, the better the classifier!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coBTFkcRNQJI"
      },
      "source": [
        "# Predict what the classes are based on the training data\n",
        "predictions = knn.predict(inputs_train)\n",
        "\n",
        "# Print the score on the training data\n",
        "print(\"KNN Training Set Score:\")\n",
        "print(accuracy_score(labels_train, predictions)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhvoEzvqNQJK"
      },
      "source": [
        "It should do pretty well on the training data, since that's what we used to teach it.  But machine learning is all about applying your machine learning method to NEW data.  So now let's see how it does on the testing set.  We're going to do the same thing, but with the testing data instead of the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgLoY5K4NQJL"
      },
      "source": [
        "# Predict what the classes are based on the testing data\n",
        "predictions = knn.predict(inputs_test)\n",
        "\n",
        "# Print the score on the testing data\n",
        "print(\"KNN Testing Set Score:\")\n",
        "print(accuracy_score(labels_test, predictions)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cICB-TqzNQJN"
      },
      "source": [
        "It still does okay, but maybe not as good as the training set.  But it clearly learned something!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkFtqE0ZNQJO"
      },
      "source": [
        "### Step 7: Let's train a neural network! ##\n",
        "\n",
        "Okay, now we're going train a neural network.  The great thing about sklearn is that all of the machine learning methods use the same structure. In this step we're going to create a neural network, and **then YOU are going to add in the training step** by writing the code to train it.  You can use the exact same structure from the knn example about for training the neural network, just change knn to nnet!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ynUhzbUNQJO"
      },
      "source": [
        "# MLP stands for multi-layer perceptron -- it's just a fancy name for the neural networks we've been working with\n",
        "\n",
        "# The hidden layer sizes specify how many layers and how many neurons per layer.  \n",
        "# Right now, there's only one hidden layer with 10 neurons, but for example, we could change that to (10,5,)\n",
        "# to make two hidden layers, one with 10 neurons and one with 5.\n",
        "\n",
        "# max_iter specifies how many training steps to use\n",
        "\n",
        "nnet = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000)\n",
        "\n",
        "# Train the NNET!\n",
        "# Here's where you add the training step for nnet!  \n",
        "# Just do the same thing we did for mlp when training, but replace mlp with nnet\n",
        "# YOU ADD CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW28_t6mNQJR"
      },
      "source": [
        "### Step 8: Let's test it! ##\n",
        "\n",
        "Now we're going to do the exact same thing we did to test knns, but for nnet! **You're going to fill in the code below, just like we did it with knn!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXV54EmFNQJS"
      },
      "source": [
        "# Predict what the classes are based on the training data\n",
        "# YOU ADD CODE HERE!\n",
        "\n",
        "\n",
        "# Print the score on the training data\n",
        "print(\"Neural Network Training Set Score:\")\n",
        "print(accuracy_score(labels_train, predictions)*100)\n",
        "\n",
        "# Predict what the classes are based on the testing data\n",
        "\n",
        "######## YOU ADD CODE HERE!\n",
        "\n",
        "\n",
        "# Print the score on the testing data\n",
        "print(\"Neural Network Testing Set Score:\")\n",
        "print(accuracy_score(labels_test, predictions)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q696Fg0bNQJW"
      },
      "source": [
        "How did the neural network do? Did it make better or worse grades than k-nearest neighbors?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9lmiyo4NQJX"
      },
      "source": [
        "## That's it! ##\n",
        "\n",
        "You've trained TWO different types of machine learning algorithms to recognize different types of irises!\n",
        "\n",
        "Want to learn more? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbsetw-WNQJX"
      },
      "source": [
        "## BONUS STEPS ##\n",
        "\n",
        "1. We set testing_size early on to be 20% of the data (by setting the value to 0.2). What happens when we change that number to 0.4? 0.6? \n",
        "\n",
        "2. What happens when you increase the number of neurons in the hidden layer in the neural network? What about decreasing the number of neurons in the hidden layer? What happens when you add more layers?\n",
        "\n",
        "3. What happens when you change the number of training iterations or steps for the neural network (change `max_iter`)? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgR8w8abNQJZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}